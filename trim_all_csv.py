import pandas as pd
import os

# Folder containing the original large CSVs
base_path = 'data/AirQualityIndia'

# CSV files to process
csv_files = [
    'city_day.csv',
    'city_hour.csv',
    'station_day.csv',
    'station_hour.csv'
]

# Number of rows to keep in each trimmed file
MAX_ROWS = 50000

# Create smaller versions of each file
for filename in csv_files:
    input_path = os.path.join(base_path, filename)
    output_filename = filename.replace('.csv', '_sample.csv')
    output_path = os.path.join(base_path, output_filename)

    if os.path.exists(input_path):
        print(f"üìÇ Trimming: {filename}")
        try:
            df = pd.read_csv(input_path, nrows=MAX_ROWS)
            df.to_csv(output_path, index=False)
            print(f"‚úÖ Saved trimmed file ‚Üí {output_path}")
        except Exception as e:
            print(f"‚ùå Error reading {filename}: {e}")
    else:
        print(f"‚ö†Ô∏è File not found: {filename}")

print("\n‚úÖ All CSVs processed. Sample files are ready.")
